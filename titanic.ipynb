{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = train[\"Survived\"]\n",
    "X_train = train.drop([\"Survived\"], axis=1)\n",
    "\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train[\"Age\"].isna().count() - train[\"Age\"].count())\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "sns.despine(left=True)\n",
    "\n",
    "sns.distplot(train[\"Age\"].dropna(), ax=axes[0,0])\n",
    "sns.distplot(train[\"Pclass\"], ax=axes[0,1], kde=False)\n",
    "sns.distplot(train[\"Parch\"], ax=axes[1,0], kde=False)\n",
    "sns.distplot(train[\"SibSp\"], ax=axes[1,1], kde=False)\n",
    "sns.distplot(train[\"Fare\"], ax=axes[2,0])\n",
    "sns.distplot(train[\"Fare\"], ax=axes[2,0])\n",
    "\n",
    "sns.catplot(x=\"Sex\", y=\"Survived\", kind=\"bar\", data=train)\n",
    "sns.catplot(x=\"Sex\", y=\"Survived\", kind=\"bar\", data=train, hue=\"Pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pclass: \", X_train[\"Pclass\"].hasnans)\n",
    "print(\"Sex: \", X_train[\"Sex\"].hasnans)\n",
    "print(\"SibSp: \", X_train[\"SibSp\"].hasnans)\n",
    "print(\"Parch: \", X_train[\"Parch\"].hasnans)\n",
    "print(\"Embarked: \", X_train[\"Embarked\"].hasnans)\n",
    "print(\"Cabin: \", X_train[\"Cabin\"].hasnans)\n",
    "print(\"Fare: \", X_train[\"Fare\"].hasnans)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = X_train.assign(Survived=y_train)\n",
    "sns.catplot(x=\"Cabin\", y=\"Survived\", kind=\"bar\", data=data, hue=\"Pclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default onehotencoder for Strings\n",
    "onehotencoder = OneHotEncoder(dtype='int', categories='auto', handle_unknown='ignore')\n",
    "\n",
    "# Impute and scale numeric values \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Impute with constant fill_value to create an UNKNOWN class and onehotencode\n",
    "onehot_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', onehotencoder)])\n",
    "\n",
    "# Change sex from male or female to child if age is smaller or equal to 16\n",
    "def mark_children(df):\n",
    "    # Mark under 16 as children and replace sex with child\n",
    "    children = df[\"Age\"] > 16\n",
    "    return df[\"Sex\"].where(children, \"child\").to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Change sex to distinguish between children, men and women\n",
    "augment_sex = Pipeline(steps = [\n",
    "    ('mark_children', FunctionTransformer(mark_children, validate=False)),\n",
    "    ('onehot', onehotencoder)\n",
    "])\n",
    "\n",
    "def take_first_char(array):\n",
    "    # Shape of array is a list of a list of words e.g. [['word1'],['word2']]     \n",
    "    return np.array([x[0][0] for x in array]).reshape(-1, 1)\n",
    "\n",
    "# Imputer with constant fill_value to create an UNKNOWN class,\n",
    "# take leading character and onehotencode\n",
    "onehot_replace_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=\"UNKNOWN\")),\n",
    "    ('replacer', FunctionTransformer(take_first_char, validate=False)),\n",
    "    ('onehot', onehotencoder)\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"onehotencode\", onehotencoder, [\"Pclass\", \"SibSp\", \"Parch\"]), # 17 features\n",
    "    (\"impute-and-onehot-embarked\", onehot_transformer, [\"Embarked\"]), # 4 features\n",
    "    (\"impute-and-onehot-cabin\", onehot_replace_transformer, [\"Cabin\"]), # 9 features\n",
    "    (\"find-children\", augment_sex, [\"Sex\", \"Age\"]), # 3 features\n",
    "    (\"impute-and-scale-age,fare\", numeric_transformer, [\"Age\", \"Fare\"]) # 2 features\n",
    "])\n",
    "\n",
    "ct.fit_transform(X_train)\n",
    "\n",
    "# print(\"Nans after transform: \", np.isnan(matrix.data).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline(\n",
    "    steps = [('data-transformer', ct),\n",
    "             ('randomforest', RandomForestClassifier(n_estimators=100))]\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforest__n_estimators': n_estimators,\n",
    "               'randomforest__max_features': max_features,\n",
    "               'randomforest__max_depth': max_depth,\n",
    "               'randomforest__min_samples_split': min_samples_split,\n",
    "               'randomforest__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforest__bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 10, \n",
    "                               verbose=2, \n",
    "                               random_state=42,\n",
    "                               n_jobs=-1\n",
    "                              )\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = model.score(test_features, test_labels)*100\n",
    "    print('Model Performance')\n",
    "#     print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(clf, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "best_random_accuracy = evaluate(best_random, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_params_)\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'randomforest__bootstrap': [True],\n",
    "    'randomforest__max_depth': [200],\n",
    "    'randomforest__max_features': [10],\n",
    "    'randomforest__min_samples_leaf': [5],\n",
    "    'randomforest__min_samples_split': [5],\n",
    "    'randomforest__n_estimators': [700]\n",
    "}\n",
    "\n",
    "est = Pipeline(\n",
    "    steps = [('data-transformer', ct),\n",
    "             ('randomforest', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = est, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = best_grid.predict(test)\n",
    "results = pd.Series(results,name=\"Survived\")\n",
    "submission = pd.concat([ test[\"PassengerId\"] ,results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"data/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 78.21%. Submitted to kaggle\n",
    "# {'randomforest__bootstrap': True,\n",
    "#  'randomforest__max_depth': 200,\n",
    "#  'randomforest__max_features': 10,\n",
    "#  'randomforest__min_samples_leaf': 5,\n",
    "#  'randomforest__min_samples_split': 5,\n",
    "#  'randomforest__n_estimators': 700}\n",
    "\n",
    "grid_search.best_params_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
